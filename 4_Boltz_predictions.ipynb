{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd89add3",
   "metadata": {},
   "source": [
    "# Make predictions using boltz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d924ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install boltz -U\n",
    "# pip install PDBParser\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from Bio import PDB\n",
    "from rdkit import Chem\n",
    "import yaml\n",
    "from Bio.PDB import PDBParser, PPBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645648b",
   "metadata": {},
   "source": [
    "### First, we define a helper functions\n",
    "\n",
    "- to extract protein seqeunce from availabe protein PDB file\n",
    "- Generate yaml files for all 300 ligands\n",
    "- Run boltz2 predictions for protein-ligand co-folding and affinity predictions inside a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_protein_sequence(pdb_file):\n",
    "    \"\"\"\n",
    "    Extracts the full protein sequence (one-letter code) from a PDB file.\n",
    "    Returns the concatenated sequence as a string.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"protein\", pdb_file)\n",
    "    ppb = PPBuilder()\n",
    "    sequences = [pp.get_sequence() for pp in ppb.build_peptides(structure)]\n",
    "    return \"\".join(str(seq) for seq in sequences)\n",
    "\n",
    "def generate_yaml_files(csv_file, pdb_file, output_dir=\"yaml_files\"):\n",
    "    \"\"\"\n",
    "    Generates YAML files for each ligand in the CSV file for Boltz-2 input.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    protein_sequence = extract_protein_sequence(pdb_file)\n",
    "    print(f\"Extracted protein sequence length: {len(protein_sequence)} residues\")\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    required_cols = {\"index_ID\", \"SMILES_Prepared\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV must contain columns: {required_cols}\")\n",
    "\n",
    "    yaml_paths = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ligand_id = str(row[\"index_ID\"])\n",
    "        smiles = str(row[\"SMILES_Prepared\"])\n",
    "\n",
    "        yaml_content = {\n",
    "            \"version\": 1,\n",
    "            \"sequences\": [\n",
    "                {\"protein\": {\"id\": \"A\", \"sequence\": protein_sequence}},\n",
    "                {\"ligand\": {\"id\": \"B\", \"smiles\": smiles}},\n",
    "            ],\n",
    "            \"properties\": [\n",
    "                {\"affinity\": {\"binder\": \"B\"}}\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        yaml_path = os.path.join(output_dir, f\"{ligand_id}.yaml\")\n",
    "        with open(yaml_path, \"w\") as f:\n",
    "            yaml.dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "        yaml_paths.append(yaml_path)\n",
    "\n",
    "    print(f\"✅ Generated {len(yaml_paths)} YAML files in '{output_dir}'\")\n",
    "    return yaml_paths\n",
    "\n",
    "\n",
    "def run_boltz_prediction(yaml_file, output_dir):\n",
    "    \"\"\"\n",
    "    Runs Boltz-2 prediction on a single YAML file inside its own output folder.\n",
    "    \"\"\"\n",
    "    ligand_name = os.path.splitext(os.path.basename(yaml_file))[0]\n",
    "    ligand_output_dir = os.path.join(output_dir, ligand_name)\n",
    "    os.makedirs(ligand_output_dir, exist_ok=True)\n",
    "\n",
    "    cmd = [\n",
    "        \"boltz\",\n",
    "        \"predict\",\n",
    "        os.path.abspath(yaml_file),\n",
    "        \"--use_msa_server\"\n",
    "    ]\n",
    "    print(f\"Running command: {cmd}\")\n",
    "\n",
    "    print(f\"▶ Running Boltz-2 for {ligand_name} ...\")\n",
    "    try:\n",
    "        subprocess.run(cmd, cwd=ligand_output_dir, check=True)\n",
    "        print(f\"✅ Completed: {ligand_name}\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed for {ligand_name}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cfa28",
   "metadata": {},
   "source": [
    "# the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d80504c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted protein sequence length: 297 residues\n",
      "✅ Generated 300 YAML files in 'all_yaml_files'\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/287.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 287 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/287.yaml with 1 protein entities.\n",
      "Calling MSA server for target 287 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:06 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.48s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:47<00:00,  0.02it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:47<00:00,  0.02it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n",
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/bin/boltz\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/main.py\", line 1406, in predict\n",
      "    trainer.predict(\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 859, in predict\n",
      "    return call._call_and_handle_interrupt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 898, in _predict_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1021, in _run_stage\n",
      "    return self.predict_loop.run()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/prediction_loop.py\", line 122, in run\n",
      "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 142, in __next__\n",
      "    out = next(self.iterators[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 219, in __getitem__\n",
      "    input_data = load_input(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 63, in load_input\n",
      "    structure = StructureV2.load(\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/types.py\", line 33, in load\n",
      "    return cls(**np.load(path, allow_pickle=True))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'boltz_results_287/predictions/287/pre_affinity_287.npz'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:01<?, ?it/s]\n",
      "❌ Failed for 287: Command '['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/287.yaml', '--use_msa_server']' returned non-zero exit status 1.\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/899.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 899 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/899.yaml with 1 protein entities.\n",
      "Calling MSA server for target 899 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:05 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.02s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:37<00:00,  0.03it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:37<00:00,  0.03it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n",
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/bin/boltz\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/main.py\", line 1406, in predict\n",
      "    trainer.predict(\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 859, in predict\n",
      "    return call._call_and_handle_interrupt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 898, in _predict_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1021, in _run_stage\n",
      "    return self.predict_loop.run()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/prediction_loop.py\", line 122, in run\n",
      "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 142, in __next__\n",
      "    out = next(self.iterators[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 219, in __getitem__\n",
      "    input_data = load_input(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 63, in load_input\n",
      "    structure = StructureV2.load(\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/types.py\", line 33, in load\n",
      "    return cls(**np.load(path, allow_pickle=True))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'boltz_results_899/predictions/899/pre_affinity_899.npz'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:02<?, ?it/s]\n",
      "❌ Failed for 899: Command '['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/899.yaml', '--use_msa_server']' returned non-zero exit status 1.\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/749.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 749 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/749.yaml with 1 protein entities.\n",
      "Calling MSA server for target 749 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:06 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.77s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [02:40<00:00,  0.01it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [02:40<00:00,  0.01it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n",
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/bin/boltz\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/main.py\", line 1406, in predict\n",
      "    trainer.predict(\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 859, in predict\n",
      "    return call._call_and_handle_interrupt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 898, in _predict_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1021, in _run_stage\n",
      "    return self.predict_loop.run()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/prediction_loop.py\", line 122, in run\n",
      "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 142, in __next__\n",
      "    out = next(self.iterators[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 219, in __getitem__\n",
      "    input_data = load_input(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 63, in load_input\n",
      "    structure = StructureV2.load(\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/types.py\", line 33, in load\n",
      "    return cls(**np.load(path, allow_pickle=True))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'boltz_results_749/predictions/749/pre_affinity_749.npz'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:01<?, ?it/s]\n",
      "❌ Failed for 749: Command '['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/749.yaml', '--use_msa_server']' returned non-zero exit status 1.\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/162.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 162 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/162.yaml with 1 protein entities.\n",
      "Calling MSA server for target 162 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:04 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/model/loss/diffusionv2.py:51: UserWarning: The operator 'aten::linalg_svd' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:15.)\n",
      "  U, S, V = torch.linalg.svd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [05:34<00:00,  0.00it/s]Number of failed examples: 0\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [05:34<00:00,  0.00it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [21:35<00:00,  0.00it/s]Number of failed examples: 0\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [21:35<00:00,  0.00it/s]\n",
      "✅ Completed: 162\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/770.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 770 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/770.yaml with 1 protein entities.\n",
      "Calling MSA server for target 770 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:09 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.83s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:16<00:00,  0.06it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:16<00:00,  0.06it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python3.12(26963) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python3.12(27035) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/bin/boltz\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/main.py\", line 1406, in predict\n",
      "    trainer.predict(\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 859, in predict\n",
      "    return call._call_and_handle_interrupt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 898, in _predict_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1021, in _run_stage\n",
      "    return self.predict_loop.run()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/prediction_loop.py\", line 122, in run\n",
      "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 142, in __next__\n",
      "    out = next(self.iterators[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 219, in __getitem__\n",
      "    input_data = load_input(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 63, in load_input\n",
      "    structure = StructureV2.load(\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/types.py\", line 33, in load\n",
      "    return cls(**np.load(path, allow_pickle=True))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'boltz_results_770/predictions/770/pre_affinity_770.npz'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:01<?, ?it/s]\n",
      "❌ Failed for 770: Command '['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/770.yaml', '--use_msa_server']' returned non-zero exit status 1.\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/773.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 773 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(27049) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/773.yaml with 1 protein entities.\n",
      "Calling MSA server for target 773 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:10 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.63s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, skipping batch\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:14<00:00,  0.07it/s]Number of failed examples: 1\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:14<00:00,  0.07it/s]\n",
      "\n",
      "Predicting property: affinity\n",
      "\n",
      "Checking input data for affinity.\n",
      "Running affinity prediction for 1 input.\n",
      "Predicting: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/bin/boltz\", line 7, in <module>\n",
      "    sys.exit(cli())\n",
      "             ^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/main.py\", line 1406, in predict\n",
      "    trainer.predict(\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 859, in predict\n",
      "    return call._call_and_handle_interrupt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 898, in _predict_impl\n",
      "    results = self._run(model, ckpt_path=ckpt_path)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py\", line 1021, in _run_stage\n",
      "    return self.predict_loop.run()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py\", line 179, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/prediction_loop.py\", line 122, in run\n",
      "    batch, batch_idx, dataloader_idx = next(data_fetcher)\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 142, in __next__\n",
      "    out = next(self.iterators[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1506, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1541, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/_utils.py\", line 769, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 219, in __getitem__\n",
      "    input_data = load_input(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/module/inferencev2.py\", line 63, in load_input\n",
      "    structure = StructureV2.load(\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/boltz/data/types.py\", line 33, in load\n",
      "    return cls(**np.load(path, allow_pickle=True))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/numpy/lib/npyio.py\", line 427, in load\n",
      "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'boltz_results_773/predictions/773/pre_affinity_773.npz'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [00:01<?, ?it/s]\n",
      "❌ Failed for 773: Command '['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/773.yaml', '--use_msa_server']' returned non-zero exit status 1.\n",
      "Running command: ['boltz', 'predict', '/Users/ganeshshahane/Work/TQ_test/all_yaml_files/779.yaml', '--use_msa_server']\n",
      "▶ Running Boltz-2 for 779 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(27207) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/Context.cpp:85.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA server enabled: https://api.colabfold.com\n",
      "MSA server authentication: no credentials provided\n",
      "Checking input data.\n",
      "Processing 1 inputs with 1 threads.\n",
      "Generating MSA for /Users/ganeshshahane/Work/TQ_test/all_yaml_files/779.yaml with 1 protein entities.\n",
      "Calling MSA server for target 779 with 1 sequences\n",
      "MSA server URL: https://api.colabfold.com\n",
      "MSA pairing strategy: greedy\n",
      "No authentication provided for MSA server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]\u001b[A\n",
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:07 remaining: 00:00]\u001b[A\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.80s/it]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running structure prediction for 1 input.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v2.5.0\n",
      "/Users/ganeshshahane/miniconda3/envs/TQ_test/lib/python3.12/multiprocessing/resource_tracker.py:279: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Run Boltz-2 predictions for each YAML file\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m yaml_file \u001b[38;5;129;01min\u001b[39;00m yaml_files:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m#print(f\"Processing {yaml_file}...\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mrun_boltz_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboltz_output_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mrun_boltz_prediction\u001b[39m\u001b[34m(yaml_file, output_dir)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m▶ Running Boltz-2 for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mligand_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mligand_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Completed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mligand_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TQ_test/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TQ_test/lib/python3.12/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TQ_test/lib/python3.12/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TQ_test/lib/python3.12/subprocess.py:2053\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2053\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2056\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TQ_test/lib/python3.12/subprocess.py:2011\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2011\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2014\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2016\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    csv_file = \"final_prepared_molecules.csv\"          # path to your CSV\n",
    "    pdb_file = \"protein_clean.pdb\"          # path to your PDB\n",
    "    yaml_dir = \"all_yaml_files\"         # directory for YAML outputs\n",
    "    boltz_output_dir = \"boltz_output\" # Directory for Boltz-2 results\n",
    "\n",
    "    yaml_files = generate_yaml_files(csv_file, pdb_file, output_dir=yaml_dir)\n",
    "    # Run Boltz-2 predictions for each YAML file\n",
    "    for yaml_file in yaml_files:\n",
    "        #print(f\"Processing {yaml_file}...\")\n",
    "        run_boltz_prediction(yaml_file, boltz_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8746cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c91a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TQ_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
